# ğŸŒ ClimateLens

Climate change is driving rising anxiety, yet we lack clear insight into how it appears in everyday language and have few tools for early detection. By analyzing linguistic patterns with NLP/LLM methods, ClimateLens aims to identify climate anxiety early, reveal how it manifests among youth, and provide a reusable, scalable detection model with an interactive platform for applying and visualizing results. The goal is to enable timely support, strengthen resilience, and turn climate-related fears into constructive engagement.

The production app is deployed on HuggingFace Spaces using Streamlit. All visualizations and explanations are present in the app.

- [ğŸŒ Launch Webapp](https://huggingface.co/spaces/crc-sprout/ClimateLens)  
- [ğŸ“– Learn More](https://crc.place/climatelens/)

## âœ¨ Features
- **Data Collection** â€“ tools for gathering and cleaning social media datasets.
- **NLP Models** â€“ topic modeling and classification for detecting climate-related emotions.
- **Visualization** â€“ interactive graphics and dashboards.
- **WebApp** â€“ HuggingFace Space using Streamlit.

## ğŸ” Required Environment Variables
```
# Cohere
COHERE_API_KEY=your_cohere_key

# Directories
DATA_DIR=your_data_directory_here
CODE_DIR=your_code_directory_here
```

Moreover, `topic_modeling.py` and `emotion_classification.py` both also require a manual entry for the .env file.

## ğŸ“‚ Project Structure
```
ClimateLens/
â”œâ”€â”€ azureml/                         # Azure Machine Learning job + environment setup
â”‚   â”œâ”€â”€ AML_job.py                   # Defines AML job configuration and execution
â”‚   â”œâ”€â”€ environment.yml              # Conda environment used for AML compute
â”‚   â”œâ”€â”€ run_scripts.sh               # Shell script for running AML jobs end-to-end
â”‚   â””â”€â”€ test_run_scripts.sh          # Test script to validate AML job execution
â”‚
â”œâ”€â”€ data/                            # Sample input datasets
â”‚   â”œâ”€â”€ climate_twitter_sample.csv   # Example climate-related Twitter posts
â”‚   â”œâ”€â”€ filtered_anticonsumption_comments.csv  # Cleaned Reddit/Twitter anti-consumption data
â”‚   â””â”€â”€ README.md                     # Notes describing sample data contents/format
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ LDA/                          # Baseline LDA topic modeling implementation
â”‚   â”‚   â””â”€â”€ ...                       # (LDA model scripts, topic extraction helpers, etc.)
â”‚   â”œâ”€â”€ data_preprocessing.py         # Cleans raw social media text, normalizes fields, removes noise
â”‚   â”œâ”€â”€ dynamic_topic_modeling.py     # Implements dynamic/temporal topic modeling (e.g., DTM/BERT-based)
â”‚   â”œâ”€â”€ emotion_classification.py     # Emotion classifier pipeline (e.g., emotion embeddings + model)
â”‚   â”œâ”€â”€ emotion_visualizations.ipynb  # Notebook for plotting emotion trends and visual insights
â”‚   â”œâ”€â”€ reddit_data_filtering.py      # Filtering + preprocessing logic specialized for Reddit datasets
â”‚   â”œâ”€â”€ topic_modeling.py             # Main topic modeling pipeline (BERTopic, LDA, clustering, etc.)
â”‚   â””â”€â”€ twitter_data_cleaner.py       # Specialized cleaning for Twitter text (URLs, mentions, tokens)
â”‚   â””â”€â”€ README.md                     # Explanation of source code structure & how to run modules
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile                         # Automation commands (e.g., setup, run, clean)
â”œâ”€â”€ pyproject.toml                   # Build system + project metadata (modern Python packaging)
â”œâ”€â”€ README.md                        # Main project documentation
â”œâ”€â”€ requirements.txt                 # Python dependencies (runtime)
â””â”€â”€ setup.cfg                        # Linting, formatting, and packaging configuration
```

# âš™ï¸ Azure ML Execution

ClimateLens supports cloud execution using Azure Machine Learning (AzureML).
All code and data should already live inside your AzureML Workspace, the jobs simply run the pipeline on a compute cluster without needing a web connection (AzureML compute instances are VMs, but JupyterNotebook requires a job to run without the web connection). Note that you must keep `AML_job.py` in the root directory outside of the azureml folder for everything to work as is.

### **How it works**

* AzureML mounts your existing workspace code and data
* A job runs your scripts in sequence using `run_all.sh`
* No local uploads or `.env` access are required
* Logs stream back to your terminal

```run_scripts.sh``` defines the order of your pipeline steps and ```AML_job.py``` submits the job to AzureML.

## ğŸ¤ Contributing
This is an organization-only project for now, but efforts are underway to make this fully open-source.

## License
This project is licensed under the MIT License. See the LICENSE file for details.